{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Read the Excel file\n",
    "data = pd.read_excel(\".\\\\datasets\\\\concrete\\\\Concrete_Data.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8e9521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to be more concise\n",
    "data.columns = ['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer', 'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Concrete Compressive Strength']\n",
    "\n",
    "target = data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636d8156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Best λ    Test Error  Baseline Error \n",
      "1    0.0001    0.1845      0.5049         \n",
      "2    0.0001    0.1553      0.5049         \n",
      "3    0.0464    0.1553      0.5049         \n",
      "4    0.0001    0.1942      0.5049         \n",
      "5    0.0001    0.1553      0.5049         \n",
      "6    0.0001    0.1262      0.5049         \n",
      "7    0.0001    0.1456      0.5049         \n",
      "8    0.0464    0.1456      0.5049         \n",
      "9    0.0001    0.1359      0.5049         \n",
      "10   0.0464    0.1553      0.5049         \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = data.copy()  # adjust path if needed\n",
    "\n",
    "# Binary classification: define \"high strength\" as strength > median\n",
    "median_strength = df['Concrete Compressive Strength'].median()\n",
    "df['target'] = (df['Concrete Compressive Strength'] > median_strength).astype(int)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['Concrete Compressive Strength', 'target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Regularization strengths to try\n",
    "lambdas = np.logspace(-4, 2, 10)\n",
    "\n",
    "# Outer CV\n",
    "K1 = 10\n",
    "K2 = 10\n",
    "outer_cv = StratifiedKFold(n_splits=K1, shuffle=True, random_state=1)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"{'Fold':<5}{'Best λ':<10}{'Test Error':<12}{'Baseline Error':<15}\")\n",
    "for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "    X_train_outer, y_train_outer = X[train_idx], y[train_idx]\n",
    "    X_test_outer, y_test_outer = X[test_idx], y[test_idx]\n",
    "\n",
    "    inner_cv = StratifiedKFold(n_splits=K2, shuffle=True, random_state=fold)\n",
    "\n",
    "    best_lambda = None\n",
    "    best_score = np.inf\n",
    "    for lam in lambdas:\n",
    "        val_errors = []\n",
    "        for inner_train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, y_train_inner = X_train_outer[inner_train_idx], y_train_outer[inner_train_idx]\n",
    "            X_val = X_train_outer[val_idx]\n",
    "            y_val = y_train_outer[val_idx]\n",
    "\n",
    "            model = LogisticRegression(C=1/lam, penalty='l2', solver='liblinear')\n",
    "            model.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            val_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "            val_errors.append(val_error)\n",
    "\n",
    "        mean_val_error = np.mean(val_errors)\n",
    "        if mean_val_error < best_score:\n",
    "            best_score = mean_val_error\n",
    "            best_lambda = lam\n",
    "\n",
    "    # Retrain on outer training with best lambda, evaluate on outer test\n",
    "    final_model = LogisticRegression(C=1/best_lambda, penalty='l2', solver='liblinear')\n",
    "    final_model.fit(X_train_outer, y_train_outer)\n",
    "    y_test_pred = final_model.predict(X_test_outer)\n",
    "    test_error = 1 - accuracy_score(y_test_outer, y_test_pred)\n",
    "\n",
    "    # Baseline: predict most frequent class in training\n",
    "    majority_class = np.bincount(y_train_outer).argmax()\n",
    "    baseline_preds = np.full_like(y_test_outer, majority_class)\n",
    "    baseline_error = 1 - accuracy_score(y_test_outer, baseline_preds)\n",
    "\n",
    "    results.append((fold, best_lambda, test_error, baseline_error))\n",
    "    print(f\"{fold:<5}{best_lambda:<10.4f}{test_error:<12.4f}{baseline_error:<15.4f}\")\n",
    "\n",
    "# Optionally save results\n",
    "df_results = pd.DataFrame(results, columns=['Fold', 'Best Lambda', 'Test Error', 'Baseline Error'])\n",
    "df_results.to_csv(\"logistic_regression_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaad6518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.8023333336920273, 5.057676786792999)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X), np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99bec9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_errors(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate classification error.\n",
    "    :param y_true: True labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: Classification error (1 - accuracy)\n",
    "    \"\"\"\n",
    "    misclassified = np.sum(y_true != y_pred)\n",
    "    COUNT = len(y_true)\n",
    "    inaccuracy = (misclassified / COUNT)\n",
    "    return inaccuracy\n",
    "\n",
    "def do_logistic_regression(inner_cv, X_train_outer, y_train_outer, X_test_outer, y_test_outer, lambdas):\n",
    "        # ---------------------------------------\n",
    "    # Inner CV for Logistic Regression\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    best_lambda = None\n",
    "    best_logreg_score = np.inf  # lower is better since we use error rate\n",
    "    for lam in lambdas:\n",
    "        val_errors = []\n",
    "        # Tune on inner folds\n",
    "        for inner_train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, y_train_inner = X_train_outer[inner_train_idx], y_train_outer[inner_train_idx]\n",
    "            X_val, y_val = X_train_outer[val_idx], y_train_outer[val_idx]\n",
    "            \n",
    "            # Note: C = 1/lam\n",
    "            model = LogisticRegression(C=1/lam, penalty='l2', solver='liblinear', max_iter=1000)\n",
    "            model.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            # Classification error = misclassified observations / N_test = 1 - accuracy\n",
    "            val_error = calculate_errors(y_val, y_val_pred)\n",
    "            val_errors.append(val_error)\n",
    "        mean_val_error = np.mean(val_errors)\n",
    "        if mean_val_error < best_logreg_score:\n",
    "            best_logreg_score = mean_val_error\n",
    "            best_lambda = lam\n",
    "\n",
    "    # Retrain logistic regression on full outer training set with best lambda\n",
    "    best_logreg = LogisticRegression(C=1/best_lambda, penalty='l2', solver='liblinear', max_iter=1000)\n",
    "    best_logreg.fit(X_train_outer, y_train_outer)\n",
    "    y_test_pred_logreg = best_logreg.predict(X_test_outer)\n",
    "    logreg_error = calculate_errors(y_test_outer, y_test_pred_logreg)\n",
    "    return best_lambda, logreg_error, y_test_pred_logreg\n",
    "\n",
    "def do_ann(inner_cv, X_train_outer, y_train_outer, X_test_outer, y_test_outer, hidden_units_list):\n",
    "    # ---------------------------------------\n",
    "    # Inner CV for ANN (MLPClassifier)\n",
    "    # ---------------------------------------\n",
    "    best_h = None\n",
    "    best_ann_score = np.inf\n",
    "    for h in hidden_units_list:\n",
    "        val_errors = []\n",
    "        for inner_train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, y_train_inner = X_train_outer[inner_train_idx], y_train_outer[inner_train_idx]\n",
    "            X_val, y_val = X_train_outer[val_idx], y_train_outer[val_idx]\n",
    "            \n",
    "            # Use early stopping to help convergence and reduce iterations.\n",
    "            model = MLPClassifier(hidden_layer_sizes=(h,), max_iter=3000,\n",
    "                                  early_stopping=True, n_iter_no_change=10,\n",
    "                                  random_state=fold)\n",
    "            model.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            val_error = calculate_errors(y_val, y_val_pred)\n",
    "            val_errors.append(val_error)\n",
    "        mean_val_error = np.mean(val_errors)\n",
    "        if mean_val_error < best_ann_score:\n",
    "            best_ann_score = mean_val_error\n",
    "            best_h = h\n",
    "\n",
    "    # Retrain ANN on full outer training set with best h\n",
    "    best_ann = MLPClassifier(hidden_layer_sizes=(best_h,), max_iter=3000,n_iter_no_change=10,\n",
    "                             random_state=fold)\n",
    "    best_ann.fit(X_train_outer, y_train_outer)\n",
    "    y_test_pred_ann = best_ann.predict(X_test_outer)\n",
    "    ann_error = calculate_errors(y_test_outer, y_test_pred_ann)\n",
    "    return best_h, ann_error, y_test_pred_ann\n",
    "\n",
    "def calculate_baseline_error(y_train_outer, y_test_outer):\n",
    "    # ---------------------------------------\n",
    "    # Baseline: Predict the majority class\n",
    "    # ---------------------------------------\n",
    "    majority_class = np.bincount(y_train_outer).argmax()\n",
    "    baseline_preds = np.full_like(y_test_outer, majority_class)\n",
    "    baseline_error = calculate_errors(y_test_outer, baseline_preds)\n",
    "    return baseline_error, baseline_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45e4c2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Best λ    LogReg Err  Best h    ANN Err     Baseline Err   \n",
      "1    0.0100    0.2718      64        0.1359      0.6699         \n",
      "2    0.0000    0.2427      64        0.0971      0.6699         \n",
      "3    0.0000    0.3301      64        0.1748      0.6699         \n",
      "4    0.0000    0.3495      64        0.1748      0.6699         \n",
      "5    0.0000    0.3301      64        0.1650      0.6699         \n",
      "6    0.0000    0.3495      64        0.1748      0.6699         \n",
      "7    0.0000    0.2427      64        0.1068      0.6602         \n",
      "8    0.0000    0.3107      64        0.2233      0.6602         \n",
      "9    0.0000    0.3786      64        0.2039      0.6602         \n",
      "10   0.0000    0.2718      64        0.1359      0.6602         \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
    "\n",
    "# -------------------------\n",
    "# Load and preprocess data\n",
    "# -------------------------\n",
    "# Change the filename/path as needed\n",
    "df = pd.read_excel(\".\\\\datasets\\\\concrete\\\\Concrete_Data.xls\")\n",
    "\n",
    "# Binning the compressive strength into 6 categories\n",
    "strength_col = 'Concrete compressive strength(MPa, megapascals) '\n",
    "# Use KBinsDiscretizer to create 6 bins based on quantiles\n",
    "kbin = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "df['target'] = kbin.fit_transform(df[[strength_col]]).astype(int)\n",
    "\n",
    "# Separate features and target; drop the original target column\n",
    "X = df.drop(columns=[strength_col, 'target']).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Normalize features: each column gets zero mean and unit variance.\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# -------------------------------\n",
    "# Hyperparameter grids to search\n",
    "# -------------------------------\n",
    "# For logistic regression, we use lambda (λ) values and note that scikit-learn's C = 1/λ.\n",
    "lambdas = np.logspace(-10, 2, 10)  # 10 values between 10^-4 and 10^2\n",
    "\n",
    "# For ANN, use the number of hidden units as the complexity controlling parameter.\n",
    "hidden_units_list = [64]  # Number of hidden units\n",
    "\n",
    "# -------------------------------------------\n",
    "# Outer cross-validation: same splits for all\n",
    "# -------------------------------------------\n",
    "K_outer = 10  # outer folds\n",
    "K_inner = 10  # inner folds for hyperparameter tuning\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=K_outer, shuffle=True, random_state=42)\n",
    "\n",
    "# This list will store: (Fold, best_lambda, logistic_error, best_h, ann_error, baseline_error)\n",
    "results = []\n",
    "\n",
    "print(f\"{'Fold':<5}{'Best λ':<10}{'LogReg Err':<12}{'Best h':<10}{'ANN Err':<12}{'Baseline Err':<15}\")\n",
    "for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "    # Outer training and test sets\n",
    "    X_train_outer, y_train_outer = X[train_idx], y[train_idx]\n",
    "    X_test_outer, y_test_outer = X[test_idx], y[test_idx]\n",
    "    \n",
    "    inner_cv = StratifiedKFold(n_splits=K_inner, shuffle=True, random_state=fold)\n",
    "\n",
    "    best_lambda, logreg_error, y_test_pred_logreg = do_logistic_regression(inner_cv, X_train_outer, y_train_outer, X_test_outer, y_test_outer, lambdas)\n",
    "    best_h, ann_error, y_test_pred_ann = do_ann(inner_cv, X_train_outer, y_train_outer, X_test_outer, y_test_outer, hidden_units_list)\n",
    "    baseline_error, baseline_preds = calculate_baseline_error(y_train_outer, y_test_outer)\n",
    "    \n",
    "    results.append((fold, best_lambda, logreg_error, best_h, ann_error, baseline_error))\n",
    "    print(f\"{fold:<5}{best_lambda:<10.4f}{logreg_error:<12.4f}{best_h:<10}{ann_error:<12.4f}{baseline_error:<15.4f}\")\n",
    "\n",
    "# Save results to CSV (optional)\n",
    "df_results = pd.DataFrame(results, columns=['Fold', 'Best Lambda', 'LogReg Error', \n",
    "                                              'Best Hidden Units', 'ANN Error', 'Baseline Error'])\n",
    "df_results.to_csv(\"combined_model_errors.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73abc499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n12 (A correct, B wrong): 19\n",
      "n21 (A wrong, B correct): 5\n",
      "Total discordant pairs, N: 24\n",
      "Estimated difference in accuracy, θ̂ = 0.5833333333333334\n",
      "p-value = 0.006610751152038574\n",
      "95% Confidence interval for θ: [0.1859, 0.8129]\n",
      "The difference between classifiers is statistically significant.\n",
      "\n",
      "n12 (A correct, B wrong): 56\n",
      "n21 (A wrong, B correct): 2\n",
      "Total discordant pairs, N: 58\n",
      "Estimated difference in accuracy, θ̂ = 0.9310344827586207\n",
      "p-value = 1.1879386363489175e-14\n",
      "95% Confidence interval for θ: [0.7657, 0.9788]\n",
      "The difference between classifiers is statistically significant.\n",
      "\n",
      "n12 (A correct, B wrong): 43\n",
      "n21 (A wrong, B correct): 3\n",
      "Total discordant pairs, N: 46\n",
      "Estimated difference in accuracy, θ̂ = 0.8695652173913043\n",
      "p-value = 4.6219383875722997e-10\n",
      "95% Confidence interval for θ: [0.6492, 0.9526]\n",
      "The difference between classifiers is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom, beta\n",
    "\n",
    "# Suppose these are your test-set results:\n",
    "# y_true: true labels (binary or multi-class; here correctness is determined by comparison)\n",
    "# y_pred_A: predictions from classifier A\n",
    "# y_pred_B: predictions from classifier B\n",
    "\n",
    "# For demonstration, we create some example arrays:\n",
    "# (In practice, replace these with your actual prediction arrays.)\n",
    "y_true = y_test_outer          # True labels\n",
    "y_pred_A = y_test_pred_ann   # Predictions from Model 1 (e.g., logistic regression)\n",
    "y_pred_B =  y_test_pred_logreg  # Predictions from Model 2 (e.g., ANN)\n",
    "y_pred_C = baseline_preds   # Predictions from Model 2 (e.g., ANN)\n",
    "\n",
    "def do_test(y_true, y_pred_1, y_pred_2):\n",
    "    # Determine correctness for each classifier:\n",
    "    correct_A = (y_true == y_pred_1)\n",
    "    correct_B = (y_true == y_pred_2)\n",
    "\n",
    "    # Compute discordant counts:\n",
    "    # n12: A correct, B wrong\n",
    "    n12 = np.sum(correct_A & (~correct_B))\n",
    "    # n21: A wrong, B correct\n",
    "    n21 = np.sum((~correct_A) & correct_B)\n",
    "\n",
    "    # Total number of discordant pairs:\n",
    "    N = n12 + n21\n",
    "\n",
    "    print(\"n12 (A correct, B wrong):\", n12)\n",
    "    print(\"n21 (A wrong, B correct):\", n21)\n",
    "    print(\"Total discordant pairs, N:\", N)\n",
    "\n",
    "    # Check that we have enough discordant pairs to compute a meaningful interval.\n",
    "    if N < 5:\n",
    "        print(\"Warning: n12+n21 < 5; confidence intervals may be unreliable.\")\n",
    "\n",
    "    # 1. Estimate the difference in accuracy:\n",
    "    theta_hat = (n12 - n21) / N\n",
    "    print(\"Estimated difference in accuracy, θ̂ =\", theta_hat)\n",
    "\n",
    "    # 2. Compute the p-value using the binomial distribution.\n",
    "    # Let m = min(n12, n21)\n",
    "    m = min(n12, n21)\n",
    "    # p-value: p = 2 * BinomCDF(m; N, 0.5)\n",
    "    p_value = 2 * binom.cdf(m, N, 0.5)\n",
    "    # Ensure p_value does not exceed 1.\n",
    "    p_value = min(p_value, 1.0)\n",
    "    print(\"p-value =\", p_value)\n",
    "\n",
    "    # 3. Compute a confidence interval for θ.\n",
    "    # We use a Beta distribution with parameters:\n",
    "    f = n12 + 1\n",
    "    g = n21 + 1\n",
    "    alpha = 0.05  # for a 95% confidence interval\n",
    "\n",
    "    # Compute lower and upper quantiles from the Beta distribution.\n",
    "    # Note: beta.ppf gives the quantile for a given cumulative probability.\n",
    "    theta_lower = 2 * beta.ppf(alpha / 2, f, g) - 1\n",
    "    theta_upper = 2 * beta.ppf(1 - alpha / 2, f, g) - 1\n",
    "\n",
    "    print(\"95% Confidence interval for θ: [{:.4f}, {:.4f}]\".format(theta_lower, theta_upper))\n",
    "\n",
    "    # Interpretation:\n",
    "    if p_value < alpha:\n",
    "        print(\"The difference between classifiers is statistically significant.\")\n",
    "    else:\n",
    "        print(\"There is no statistically significant difference between the classifiers.\")\n",
    "        \n",
    "do_test(y_true, y_pred_A, y_pred_B)\n",
    "print(\"\")\n",
    "do_test(y_true, y_pred_A, y_pred_C)\n",
    "print(\"\")\n",
    "do_test(y_true, y_pred_B, y_pred_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0a7e36a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 0.2766990291262136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "the_best_lambda = 0.000001 # I am not sure what the best lambda is, so I will use a small value for now.\n",
    "model = LogisticRegression(C=1/the_best_lambda, penalty='l2', solver='liblinear', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to predict on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "print(\"Error rate:\" , calculate_errors(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
