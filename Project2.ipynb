{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c176b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def do_inner_fold(getModel, inner_cv, X_train_outer, y_train_outer, X_test_outer, lambdas):\n",
    "        # ---------------------------------------\n",
    "    # Inner CV for Logistic Regression\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    best_lambda = None\n",
    "    best_logreg_score = np.inf  # lower is better since we use error rate\n",
    "    for lam in lambdas:\n",
    "        val_errors = []\n",
    "        # Tune on inner folds\n",
    "        for inner_train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, y_train_inner = X_train_outer[inner_train_idx], y_train_outer[inner_train_idx]\n",
    "            X_val, y_val = X_train_outer[val_idx], y_train_outer[val_idx]\n",
    "            \n",
    "            # Note: C = 1/lam\n",
    "            model = getModel(lam)\n",
    "            model.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            # Classification error = misclassified observations / N_test = 1 - accuracy\n",
    "            val_error = calculate_errors(y_val, y_val_pred)\n",
    "            # overfitting error = calculate_errors(y_train_inner, model.predict(X_train_inner)) # degugging purpose\n",
    "            # print(f\"(overfitting check) Validation error for lambda {lam}: {:.4f},  {val_error:.4f}\") # degugging purpose\n",
    "            val_errors.append(val_error)\n",
    "        mean_val_error = np.mean(val_errors)\n",
    "        if mean_val_error < best_logreg_score:\n",
    "            best_logreg_score = mean_val_error\n",
    "            best_lambda = lam\n",
    "\n",
    "    # Retrain logistic regression on full outer training set with best lambda\n",
    "    best_logreg = getModel(best_lambda)\n",
    "    best_logreg.fit(X_train_outer, y_train_outer)\n",
    "    y_test_pred_logreg = best_logreg.predict(X_test_outer)\n",
    "    \n",
    "    return best_lambda, y_test_pred_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bec9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def calculate_errors(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate classification error.\n",
    "    :param y_true: True labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: Classification error (1 - accuracy)\n",
    "    \"\"\"\n",
    "    misclassified = np.sum(y_true != y_pred)\n",
    "    COUNT = len(y_true)\n",
    "    inaccuracy = (misclassified / COUNT)\n",
    "    return inaccuracy\n",
    "\n",
    "def do_logistic_regression(inner_cv, X_train_outer, y_train_outer, X_test_outer, lambdas):\n",
    "        # ---------------------------------------\n",
    "    # Inner CV for Logistic Regression\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    best_lambda = None\n",
    "    best_logreg_score = np.inf  # lower is better since we use error rate\n",
    "    for lam in lambdas:\n",
    "        val_errors = []\n",
    "        # Tune on inner folds\n",
    "        for inner_train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, y_train_inner = X_train_outer[inner_train_idx], y_train_outer[inner_train_idx]\n",
    "            X_val, y_val = X_train_outer[val_idx], y_train_outer[val_idx]\n",
    "            \n",
    "            # Note: C = 1/lam\n",
    "            model = LogisticRegression(C=1/lam, penalty='l2', solver='liblinear', max_iter=1000)\n",
    "            model.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            # Classification error = misclassified observations / N_test = 1 - accuracy\n",
    "            val_error = calculate_errors(y_val, y_val_pred)\n",
    "            val_errors.append(val_error)\n",
    "        mean_val_error = np.mean(val_errors)\n",
    "        if mean_val_error < best_logreg_score:\n",
    "            best_logreg_score = mean_val_error\n",
    "            best_lambda = lam\n",
    "\n",
    "    # Retrain logistic regression on full outer training set with best lambda\n",
    "    best_logreg = LogisticRegression(C=1/best_lambda, penalty='l2', solver='liblinear', max_iter=1000)\n",
    "    best_logreg.fit(X_train_outer, y_train_outer)\n",
    "    y_test_pred_logreg = best_logreg.predict(X_test_outer)\n",
    "    \n",
    "    return best_lambda, y_test_pred_logreg\n",
    "\n",
    "def do_ann(inner_cv, X_train_outer, y_train_outer, X_test_outer, hidden_units_list):\n",
    "    # ---------------------------------------\n",
    "    # Inner CV for ANN (MLPClassifier)\n",
    "    # ---------------------------------------\n",
    "    best_h = None\n",
    "    best_ann_score = np.inf\n",
    "    for h in hidden_units_list:\n",
    "        val_errors = []\n",
    "        for inner_train_idx, val_idx in inner_cv.split(X_train_outer, y_train_outer):\n",
    "            X_train_inner, y_train_inner = X_train_outer[inner_train_idx], y_train_outer[inner_train_idx]\n",
    "            X_val, y_val = X_train_outer[val_idx], y_train_outer[val_idx]\n",
    "            \n",
    "            # Use early stopping to help convergence and reduce iterations.\n",
    "            model = MLPClassifier(hidden_layer_sizes=(h,), max_iter=3000,\n",
    "                                  early_stopping=True, n_iter_no_change=10)\n",
    "            model.fit(X_train_inner, y_train_inner)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            val_error = calculate_errors(y_val, y_val_pred)\n",
    "            val_errors.append(val_error)\n",
    "        mean_val_error = np.mean(val_errors)\n",
    "        if mean_val_error < best_ann_score:\n",
    "            best_ann_score = mean_val_error\n",
    "            best_h = h\n",
    "\n",
    "    # Retrain ANN on full outer training set with best h\n",
    "    best_ann = MLPClassifier(hidden_layer_sizes=(best_h,), max_iter=3000,n_iter_no_change=10)\n",
    "    best_ann.fit(X_train_outer, y_train_outer)\n",
    "    y_test_pred_ann = best_ann.predict(X_test_outer)\n",
    "    return best_h, y_test_pred_ann\n",
    "\n",
    "def calculate_baseline_predictions(y_train_outer, y_test_outer):\n",
    "    # ---------------------------------------\n",
    "    # Baseline: Predict the majority class\n",
    "    # ---------------------------------------\n",
    "    majority_class = np.bincount(y_train_outer).argmax()\n",
    "    baseline_preds = np.full_like(y_test_outer, majority_class)\n",
    "    return baseline_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c91054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer, StandardScaler\n",
    "def get_parameters_and_target():\n",
    "    # -------------------------\n",
    "    # Load and preprocess data\n",
    "    # -------------------------\n",
    "    # Change the filename/path as needed\n",
    "    df = pd.read_excel(\".\\\\datasets\\\\concrete\\\\Concrete_Data.xls\")\n",
    "\n",
    "    # Binning the compressive strength into 6 categories\n",
    "    strength_col = 'Concrete compressive strength(MPa, megapascals) '\n",
    "    # Use KBinsDiscretizer to create 6 bins based on quantiles\n",
    "    kbin = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "    df['target'] = kbin.fit_transform(df[[strength_col]]).astype(int)\n",
    "\n",
    "    # Separate features and target; drop the original target column\n",
    "    X = df.drop(columns=[strength_col, 'target']).values\n",
    "    y = df['target'].values\n",
    "\n",
    "    # Normalize features: each column gets zero mean and unit variance.\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X,y = get_parameters_and_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e4c2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Best λ    LogReg Err  Best h    ANN Err     Baseline Err   \n",
      "1    0.0264    0.2718      2048      0.1359      0.6699         \n",
      "2    0.0000    0.2427      1024      0.1456      0.6699         \n",
      "3    0.0000    0.3301      1024      0.1748      0.6699         \n",
      "4    0.0000    0.3495      256       0.1650      0.6699         \n",
      "5    0.0000    0.3301      128       0.1456      0.6699         \n",
      "6    0.0000    0.3495      256       0.1942      0.6699         \n",
      "7    0.2976    0.2330      2048      0.1165      0.6602         \n",
      "8    0.0000    0.3107      512       0.1650      0.6602         \n",
      "9    0.0000    0.3786      2048      0.1650      0.6602         \n",
      "10   0.0000    0.2718      1024      0.0874      0.6602         \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def do_two_layer_cv(X, y):\n",
    "\n",
    "    # -------------------------------\n",
    "    # Hyperparameter grids to search\n",
    "    # -------------------------------\n",
    "    # For logistic regression, we use lambda (λ) values and note that scikit-learn's C = 1/λ.\n",
    "    lambdas = np.logspace(-10, 10, 20)  # 10 values between 10^-4 and 10^2\n",
    "\n",
    "    # For ANN, use the number of hidden units as the complexity controlling parameter.\n",
    "    hidden_units_list = [64, 128, 256, 512, 1024, 2048, 4096]\n",
    "\n",
    "    # -------------------------------------------\n",
    "    # Outer cross-validation: same splits for all\n",
    "    # -------------------------------------------\n",
    "    K_outer = 10  # outer folds\n",
    "    K_inner = 10  # inner folds for hyperparameter tuning\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=K_outer, shuffle=True, random_state=42)\n",
    "\n",
    "    # This list will store: (Fold, best_lambda, logistic_error, best_h, ann_error, baseline_error)\n",
    "    results = []\n",
    "    target_predictions = np.empty((len(y), 4), dtype=int)\n",
    "\n",
    "    print(f\"{'Fold':<5}{'Best λ':<10}{'LogReg Err':<12}{'Best h':<10}{'ANN Err':<12}{'Baseline Err':<15}\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "        # Outer training and test sets\n",
    "        X_train_outer, y_train_outer = X[train_idx], y[train_idx]\n",
    "        X_test_outer, y_test_outer = X[test_idx], y[test_idx]\n",
    "        \n",
    "        inner_cv = StratifiedKFold(n_splits=K_inner, shuffle=True, random_state=fold)\n",
    "\n",
    "        getLogisticRegModel = lambda lam: LogisticRegression(C=1/lam, penalty='l2', solver='liblinear', max_iter=1000)\n",
    "        best_lambda, y_test_pred_logreg = do_inner_fold(getLogisticRegModel, inner_cv, X_train_outer, y_train_outer, X_test_outer, lambdas)\n",
    "        logreg_error = calculate_errors(y_test_outer, y_test_pred_logreg)\n",
    "        \n",
    "        getAnnModel = lambda h: MLPClassifier(hidden_layer_sizes=(h,), max_iter=3000, n_iter_no_change=10)\n",
    "        best_h, y_test_pred_ann = do_inner_fold(getAnnModel, inner_cv, X_train_outer, y_train_outer, X_test_outer, hidden_units_list)\n",
    "        ann_error = calculate_errors(y_test_outer, y_test_pred_ann)\n",
    "        \n",
    "        baseline_preds = calculate_baseline_predictions(y_train_outer, y_test_outer)\n",
    "        baseline_error = calculate_errors(y_test_outer, baseline_preds)\n",
    "        \n",
    "        # Store predictions for the current fold\n",
    "        target_predictions[test_idx, 0] = y_test_outer\n",
    "        target_predictions[test_idx, 1] = y_test_pred_ann\n",
    "        target_predictions[test_idx, 2] = y_test_pred_logreg\n",
    "        target_predictions[test_idx, 3] = baseline_preds\n",
    "        \n",
    "        results.append((fold, best_lambda, logreg_error, best_h, ann_error, baseline_error))\n",
    "        print(f\"{fold:<5}{best_lambda:<10.4f}{logreg_error:<12.4f}{best_h!s:<10}{ann_error:<12.4f}{baseline_error:<15.4f}\")\n",
    "\n",
    "    # Save results to CSV (optional)\n",
    "    df_results = pd.DataFrame(results, columns=['Fold', 'Best Lambda', 'LogReg Error', \n",
    "                                                'Best Hidden Units', 'ANN Error', 'Baseline Error'])\n",
    "    df_results.to_csv(\"combined_model_errors.csv\", index=False)\n",
    "    \n",
    "    df_target_predictions = pd.DataFrame(target_predictions, columns=['original', 'ann_pred', 'logistic_reg_pred', 'baseline_pred'])\n",
    "    \n",
    "    return df_results, df_target_predictions\n",
    "    \n",
    "df_results, df_target_predictions = do_two_layer_cv(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73abc499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n12 (A correct, B wrong): 212\n",
      "n21 (A wrong, B correct): 50\n",
      "Total discordant pairs, N: 262\n",
      "Estimated difference in accuracy, θ̂ = 0.6183206106870229\n",
      "p-value = 6.4013046448738265e-25\n",
      "95% Confidence interval for θ: [0.5143, 0.7041]\n",
      "The difference between classifiers is statistically significant.\n",
      "\n",
      "n12 (A correct, B wrong): 567\n",
      "n21 (A wrong, B correct): 35\n",
      "Total discordant pairs, N: 602\n",
      "Estimated difference in accuracy, θ̂ = 0.8837209302325582\n",
      "p-value = 8.759798574601064e-125\n",
      "95% Confidence interval for θ: [0.8404, 0.9157]\n",
      "The difference between classifiers is statistically significant.\n",
      "\n",
      "n12 (A correct, B wrong): 411\n",
      "n21 (A wrong, B correct): 41\n",
      "Total discordant pairs, N: 452\n",
      "Estimated difference in accuracy, θ̂ = 0.8185840707964602\n",
      "p-value = 6.376403079492849e-78\n",
      "95% Confidence interval for θ: [0.7584, 0.8647]\n",
      "The difference between classifiers is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom, beta\n",
    "\n",
    "def do_test(y_true, y_pred_1, y_pred_2):\n",
    "    # Determine correctness for each classifier:\n",
    "    correct_A = (y_true == y_pred_1)\n",
    "    correct_B = (y_true == y_pred_2)\n",
    "\n",
    "    # Compute discordant counts:\n",
    "    # n12: A correct, B wrong\n",
    "    n12 = np.sum(correct_A & (~correct_B))\n",
    "    # n21: A wrong, B correct\n",
    "    n21 = np.sum((~correct_A) & correct_B)\n",
    "\n",
    "    # Total number of discordant pairs:\n",
    "    N = n12 + n21\n",
    "\n",
    "    print(\"n12 (A correct, B wrong):\", n12)\n",
    "    print(\"n21 (A wrong, B correct):\", n21)\n",
    "    print(\"Total discordant pairs, N:\", N)\n",
    "\n",
    "    # Check that we have enough discordant pairs to compute a meaningful interval.\n",
    "    if N < 5:\n",
    "        print(\"Warning: n12+n21 < 5; confidence intervals may be unreliable.\")\n",
    "\n",
    "    # 1. Estimate the difference in accuracy:\n",
    "    theta_hat = (n12 - n21) / N\n",
    "    print(\"Estimated difference in accuracy, θ̂ =\", theta_hat)\n",
    "\n",
    "    # 2. Compute the p-value using the binomial distribution.\n",
    "    # Let m = min(n12, n21)\n",
    "    m = min(n12, n21)\n",
    "    # p-value: p = 2 * BinomCDF(m; N, 0.5)\n",
    "    p_value = 2 * binom.cdf(m, N, 0.5)\n",
    "    # Ensure p_value does not exceed 1.\n",
    "    p_value = min(p_value, 1.0)\n",
    "    print(\"p-value =\", p_value)\n",
    "\n",
    "    # 3. Compute a confidence interval for θ.\n",
    "    # We use a Beta distribution with parameters:\n",
    "    f = n12 + 1\n",
    "    g = n21 + 1\n",
    "    alpha = 0.05  # for a 95% confidence interval\n",
    "\n",
    "    # Compute lower and upper quantiles from the Beta distribution.\n",
    "    # Note: beta.ppf gives the quantile for a given cumulative probability.\n",
    "    theta_lower = 2 * beta.ppf(alpha / 2, f, g) - 1\n",
    "    theta_upper = 2 * beta.ppf(1 - alpha / 2, f, g) - 1\n",
    "\n",
    "    print(\"95% Confidence interval for θ: [{:.4f}, {:.4f}]\".format(theta_lower, theta_upper))\n",
    "\n",
    "    # Interpretation:\n",
    "    if p_value < alpha:\n",
    "        print(\"The difference between classifiers is statistically significant.\")\n",
    "    else:\n",
    "        print(\"There is no statistically significant difference between the classifiers.\")\n",
    "        \n",
    "\n",
    "# Suppose these are your test-set results:\n",
    "# y_true: true labels (binary or multi-class; here correctness is determined by comparison)\n",
    "# y_pred_A: predictions from classifier A\n",
    "# y_pred_B: predictions from classifier B\n",
    "\n",
    "# For demonstration, we create some example arrays:\n",
    "# (In practice, replace these with your actual prediction arrays.)\n",
    "y_true = df_target_predictions['original'].values  # True labels\n",
    "y_pred_A = df_target_predictions['ann_pred'].values  # Predictions from Model 1 (e.g., ANN)\n",
    "y_pred_B =  df_target_predictions['logistic_reg_pred'].values  # Predictions from Model 2 (e.g., Logistic Regression)\n",
    "y_pred_C = df_target_predictions['baseline_pred'].values  # Predictions from Model 3 (e.g., Baseline)\n",
    "\n",
    "do_test(y_true, y_pred_A, y_pred_B)\n",
    "print(\"\")\n",
    "do_test(y_true, y_pred_A, y_pred_C)\n",
    "print(\"\")\n",
    "do_test(y_true, y_pred_B, y_pred_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7132ee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Error (Full Dataset): 0.2524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def train_final_best_logreg_model(X, y, df_results: pd.DataFrame):\n",
    "    # Retrain the best logistic regression model on the entire dataset\n",
    "    # Split the entire dataset into training and testing sets\n",
    "    X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    # Retrain the best logistic regression model on the full training set\n",
    "    best_lambda = df_results['Best Lambda'].median()  # Get the best lambda from the results\n",
    "    best_logreg_full = LogisticRegression(C=1/best_lambda, penalty='l2', solver='liblinear', max_iter=1000)\n",
    "    best_logreg_full.fit(X_train_full, y_train_full)\n",
    "    y_test_pred_logreg_full = best_logreg_full.predict(X_test_full)\n",
    "    logreg_error_full = calculate_errors(y_test_full, y_test_pred_logreg_full)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Logistic Regression Error (Full Dataset): {logreg_error_full:.4f}\")\n",
    "\n",
    "train_final_best_logreg_model(X, y, df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f2afb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 4 features: [0, 1, 2, 7]\n",
      "Final model error rate: 0.3951 ± 0.0698\n",
      "Selected features after backward selection: [0, 1, 2, 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def backward_selection_sklearn(X, y, significance_level=0.05):\n",
    "    \"\"\"\n",
    "    Perform backward selection using sklearn's recursive feature elimination\n",
    "    \n",
    "    :param X: Feature matrix (numpy array)\n",
    "    :param y: Target vector (numpy array)\n",
    "    :param significance_level: Not directly used with RFE but kept for interface consistency\n",
    "    :return: List of selected features\n",
    "    \"\"\"\n",
    "    # Get feature names or indices\n",
    "    n_features = X.shape[1]\n",
    "    feature_indices = list(range(n_features))\n",
    "    \n",
    "    # Initialize the base model\n",
    "    base_model = LogisticRegression(C=1/(10**(-10)), penalty='l2', solver='liblinear', max_iter=1000)\n",
    "    \n",
    "    # Step 1: Use RFE to rank features\n",
    "    # Start with at least half the features\n",
    "    min_features = max(1, n_features // 2)\n",
    "    \n",
    "    # Initialize RFE with the model\n",
    "    rfe = RFE(estimator=base_model, n_features_to_select=min_features, step=1)\n",
    "    rfe.fit(X, y)\n",
    "    \n",
    "    # Get the ranking of features (lower is better)\n",
    "    feature_ranking = rfe.ranking_\n",
    "    \n",
    "    # Find the selected features\n",
    "    selected_features = [i for i, rank in enumerate(feature_ranking) if rank == 1]\n",
    "    \n",
    "    print(f\"Selected {len(selected_features)} features: {selected_features}\")\n",
    "    \n",
    "    # Evaluate performance with selected features\n",
    "    if selected_features:\n",
    "        model = LogisticRegression(C=1/(10**(-10)), penalty='l2', solver='liblinear', max_iter=1000)\n",
    "        accuracy_scores = cross_val_score(model, X[:, selected_features], y, cv=5, scoring='accuracy')\n",
    "        error_scores = 1 - accuracy_scores\n",
    "        print(f\"Final model error rate: {error_scores.mean():.4f} ± {error_scores.std():.4f}\")\n",
    "    else:\n",
    "        print(\"No features were selected\")\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Perform backward selection\n",
    "selected_features = backward_selection_sklearn(X, y)\n",
    "\n",
    "print(\"Selected features after backward selection:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ac880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
